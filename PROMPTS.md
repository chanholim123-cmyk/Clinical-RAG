# System Prompt Strategy: NG12 Clinical Decision Support Agent

## Executive Summary

This document outlines the prompt engineering strategy for the Risk Assessor Agent, a clinical decision support system built on Google Vertex AI (Gemini 1.5 Pro) designed to assess cancer risk using the NICE NG12 guideline "Suspected cancer: recognition and referral." The system uses a structured four-step process (RETRIEVE → SEARCH → REASON → CLASSIFY) combined with function calling to ensure grounded, safe, and clinically appropriate recommendations.

---

## 1. Prompt Architecture Overview

The system prompt follows a hierarchical architecture designed to balance two competing requirements: autonomous clinical reasoning and safety-critical guardrails. Rather than treating the prompt as a monolithic instruction set, we structure it as four distinct layers:

**Layer 1: Role Definition** anchors the agent's identity and scope to NG12 exclusively, preventing drift into general medical advice or alternative frameworks.

**Layer 2: Procedural Framework** provides a deterministic, step-by-step workflow that maps cleanly onto the function calling capabilities of Gemini 1.5 Pro. This creates predictable, auditable reasoning chains.

**Layer 3: Domain Knowledge Injection** embeds NG12-specific terminology, thresholds, and decision logic directly into the prompt, reducing reliance on parametric knowledge and increasing RAG grounding.

**Layer 4: Safety & Output Enforcement** specifies strict JSON schema, guardrails, and disclaimers that prevent hallucination and ensure clinical appropriateness.

This layered approach enables the model to reason deeply about individual cases while maintaining tight control over output format and safety boundaries. The architecture was chosen specifically because clinical decision support requires both **interpretability** (a domain expert must understand the reasoning) and **safety** (the system must never claim certainty it doesn't possess).

---

## 2. Role & Persona Framing

The prompt explicitly establishes the agent as an "NG12 Clinical Decision Support Agent" rather than a "medical advisor," "clinician," or "health AI." This framing is critical for three reasons.

First, it creates **scope containment**. By naming the guideline explicitly, we signal that the agent's knowledge domain is bounded to one specific, well-defined document (NICE NG12) rather than the infinite space of medical knowledge. This prevents the model from invoking parametric knowledge about cancer risk factors from its training data when a guideline criterion would be more appropriate. When asked about a symptom not covered in NG12, the agent will say "Insufficient evidence for NG12-based referral" rather than improvising from general medical knowledge.

Second, it establishes **role-specific constraints**. A "clinician" would be expected to make definitive diagnoses. A "Clinical Decision Support Agent" explicitly supports human decision-making—this distinction is embedded in the role name itself. The final disclaimer ("This assessment is generated by an AI system and must be reviewed by a qualified healthcare professional") flows naturally from the role, rather than appearing as an afterthought.

Third, it enables **guideline fidelity**. NG12 uses precise terminology ("suspected cancer pathway referral," "persistent," "unexplained") that differs from common medical English. By framing the agent as specifically an NG12 agent, we create strong linguistic priors that favor this technical vocabulary over synonymous terms. For instance, if asked about a "long-standing cough," the agent will search for NG12's definition of "persistent" rather than treating "long-standing" as interchangeable.

---

## 3. Structured Process Chain: RETRIEVE → SEARCH → REASON → CLASSIFY

The four-step process is the backbone of the prompt architecture. Each step serves a distinct function in the reasoning pipeline, and together they create an auditable decision trail.

**RETRIEVE (Step 1)** is the anchor point. By explicitly requiring a call to `get_patient_record` before any reasoning, we ensure that the agent operates on actual patient data, not assumptions. This step is non-negotiable—the prompt instructs the model to "call `get_patient_record` with the provided Patient ID" as the first action, before any searching or reasoning. This prevents the agent from reasoning about a hypothetical patient and then discovering midway that the input was a real case. The RETRIEVE step also establishes the "ground truth" for all subsequent retrieval queries—age, gender, smoking history, and symptom duration are fixed facts from this step.

**SEARCH (Step 2)** operationalizes RAG grounding. Rather than a single monolithic search ("cancer risk assessment for this patient"), we require targeted searches for EACH symptom, each search combining the symptom name, patient demographics, and relevant risk factors. This multiple-query strategy achieves two goals. First, it significantly improves retrieval quality—NG12 sections are organized by cancer site and symptom, so combining "cough," "age 60," and "smoking history" retrieves more relevant passages than "assess cancer risk." Second, it creates a clear record of which guideline passages informed which conclusions, enabling clinical review.

**REASON (Step 3)** is where clinical inference happens. After all retrieval is complete, the agent cross-references the full clinical picture against the retrieved passages. Crucially, this step explicitly lists the criteria to evaluate: age thresholds, symptom combinations, symptom duration, risk factor modification, and multi-site possibilities. By enumerating these criteria, we guide the model's attention toward NG12's decision logic rather than letting it invent its own reasoning framework. This step is deliberately sequential (comes after retrieval, before classification) so that retrieved guideline passages are the primary input to reasoning.

**CLASSIFY (Step 4)** constrains output to a predefined, NG12-specific taxonomy. Rather than allowing the agent to report urgency as "high," "moderate," "low," or any other scheme, we restrict classification to six categories: suspected cancer pathway referral, very urgent, urgent investigation, non-urgent, consider investigation / safety netting, and no NG12 criteria met. This constraint prevents drift and ensures consistency across cases. Importantly, these six categories are **drawn directly from NG12's language** (not AI-invented labels), which means downstream systems and clinical staff are already familiar with them.

The reason for this sequential flow—retrieve, then search, then reason, then classify—is to create a **funnel that progressively narrows possibility space**. Initially, we have one patient and zero guideline context. After RETRIEVE, we have concrete demographics and symptoms. After SEARCH, we have relevant guideline passages. After REASON, we have a set of candidate referral paths. After CLASSIFY, we have a single, actionable recommendation. This funnel structure makes the reasoning transparent and auditable.

---

## 4. Tool Definitions & Function Calling Strategy

The system prompt references two primary tools, and their definitions are crucial to shaping model behavior.

**Tool 1: `get_patient_record`**

```json
{
  "name": "get_patient_record",
  "description": "Retrieves complete clinical record for a patient, including demographics (age, gender), smoking history, presenting symptoms, and symptom duration.",
  "parameters": {
    "type": "object",
    "properties": {
      "patient_id": {
        "type": "string",
        "description": "Unique patient identifier"
      }
    },
    "required": ["patient_id"]
  },
  "returns": {
    "type": "object",
    "properties": {
      "patient_id": {"type": "string"},
      "age": {"type": "integer"},
      "gender": {"type": "string"},
      "smoking_status": {"type": "string", "enum": ["never", "ex-smoker", "current"]},
      "symptoms": {
        "type": "array",
        "items": {
          "type": "object",
          "properties": {
            "symptom_name": {"type": "string"},
            "duration_days": {"type": "integer"},
            "severity": {"type": "string", "enum": ["mild", "moderate", "severe"]},
            "notes": {"type": "string"}
          }
        }
      }
    }
  }
}
```

This tool is intentionally narrow—it returns only demographic and symptomatic data, not preliminary diagnoses or clinician opinions. This narrowness is a feature, not a limitation. By forcing the agent to work from raw symptoms and demographics, we ensure that the guideline's logic (not embedded clinical assessments) drives the referral decision.

**Tool 2: `search_ng12_guidelines`**

```json
{
  "name": "search_ng12_guidelines",
  "description": "Searches the NG12 guideline corpus using semantic similarity. Returns relevant passages with section IDs, enabling citation and verification.",
  "parameters": {
    "type": "object",
    "properties": {
      "query": {
        "type": "string",
        "description": "Search query combining symptom name, patient context (age/gender), and risk factors. Example: 'persistent cough shortness of breath lung cancer referral aged 45 ex-smoker'"
      },
      "max_results": {
        "type": "integer",
        "description": "Maximum number of passages to return (default 5)",
        "default": 5
      }
    },
    "required": ["query"]
  },
  "returns": {
    "type": "array",
    "items": {
      "type": "object",
      "properties": {
        "section_id": {"type": "string", "description": "NG12 section reference (e.g., '1.2.5')"},
        "passage_text": {"type": "string"},
        "relevance_score": {"type": "number"}
      }
    }
  }
}
```

The design of this tool deliberately emphasizes the **query construction strategy**. The schema description includes an explicit example ("persistent cough shortness of breath lung cancer referral aged 45 ex-smoker") showing the agent how to combine symptom, cancer site, and context. This example serves as an in-context learning demonstration—by showing the preferred query format, we guide the model toward effective searches without constraining it to rigid templates. The return of `section_id` enables citations and allows downstream verification, making the recommendation traceable to source material.

**Function Calling Strategy**

The two-tool design creates a specific calling pattern. First, `get_patient_record` is called once. Then, `search_ng12_guidelines` is called multiple times—once for each symptom, with queries tailored to that symptom's context. This creates an N+1 calling pattern (one retrieve, N searches) that maps neatly onto Gemini's agentic loop. The pattern also ensures that the agent doesn't prematurely classify urgency—it must search before reasoning, search before classifying. This enforces the sequential logic we designed.

---

## 5. Domain-Specific Terminology Injection

NG12's language is precise and clinically meaningful. The prompt embeds this terminology explicitly to prevent the model from substituting common synonyms and losing clinical meaning.

The prompt includes a "NG12 Key Terminology" section that defines three critical terms: "unexplained" (symptoms not yet diagnosed after initial assessment), "persistent" (continuing beyond a period normally associated with self-limiting problems), and "suspected cancer pathway referral" (diagnosis or rule-out within 28 days). These definitions appear in the prompt, not in retrieved guideline passages, for a reason.

By embedding these definitions, we create strong priors in the model's token probability distribution. When the model encounters the word "persistent" in a retrieved passage, it will interpret it through the embedded definition, not through parametric knowledge or common usage. If a guideline says "persistent cough suggests urgent referral for lung cancer screening in patients over 40," the model will not dilute "persistent" to mean "any cough lasting more than a few days"—it will adhere to the specific NG12 definition.

This terminology injection also prevents **creep** toward weaker criteria. A clinician might say "the patient has had this symptom for a while," which in conversational English could mean two weeks. But NG12's definition of "persistent" is more specific. By anchoring the term in the prompt, we prevent the model from accepting a weakly-supported "persistent" claim from free-text patient notes.

Another critical dimension of terminology injection is the **referral taxonomy**. The prompt specifies exactly six referral categories, drawn from NG12's language. This prevents the model from inventing intermediate categories ("moderately urgent," "consider urgent consideration") or borrowing from other frameworks. The six categories are:

- Suspected cancer pathway referral (2-week wait pathway)
- Very urgent referral (within 48 hours)
- Urgent investigation (within 2 weeks)
- Non-urgent referral
- Consider investigation / safety netting
- No NG12 criteria met—standard care

By restricting to these six, we ensure consistency and prevent vague recommendations. A recommendation must be one of these six; if the agent is uncertain, it must classify as "Consider investigation / safety netting," not hedge between categories.

---

## 6. Output Schema Enforcement

The prompt specifies a strict JSON output format that serves multiple purposes beyond mere structuring.

```json
{
  "patient_id": "...",
  "patient_summary": { ... },
  "risk_assessment": {
    "identified_cancer_risks": [...],
    "overall_urgency": "...",
    "referral_recommendation": "..."
  },
  "reasoning": "...",
  "citations": [...]
}
```

First, the schema **prevents vagueness**. By requiring `identified_cancer_risks` as an array, we force the agent to enumerate specific cancers (lung, colorectal, etc.) rather than saying "possible malignancy." By requiring `overall_urgency` to be a single string (constrained to the six categories), we prevent hedge statements like "urgent or non-urgent depending on context."

Second, the schema **enforces explicitness**. The `reasoning` field requires the agent to articulate its logic, not just output a classification. The `citations` field requires traceable linkage to guideline passages. Together, these fields make the recommendation auditable—a clinician can read the reasoning and citations, verify them against the guideline, and accept or override the recommendation.

Third, the schema **enables downstream integration**. Downstream systems (EHR, referral management, alert systems) can parse the JSON and extract specific fields. The `patient_summary` field can populate referral letters. The `citations` field can generate audit trails. The `risk_assessment` field can trigger alerts if urgency is high.

---

## 7. Safety & Guardrails

Three explicit safety rules anchor the prompt:

**Rule 1: "NEVER invent criteria not found in the retrieved guidelines."** This rule prevents hallucination of guideline content. If the agent cannot find a guideline passage supporting a referral, it must say so explicitly. This rule forces fidelity to NG12, not to parametric knowledge. A clinician might know that unintentional weight loss is a cancer red flag—and NG12 may or may not mention it specifically—but the agent must only cite NG12 passages, not general knowledge.

**Rule 2: "If the retrieved passages do not clearly support a referral, state 'Insufficient evidence for NG12-based referral' and recommend safety netting."** This rule operationalizes clinical conservatism. Rather than defaulting to "no referral" (which could miss cancer), it defaults to "insufficient evidence but consider safety netting" (which maintains vigilance). Safety netting—patient education about red flags and return-if criteria—is an NG12 concept that bridges the gap between "definitely refer" and "no action."

**Rule 3: "Always err on the side of caution: if criteria are borderline met, recommend the more urgent pathway."** This rule breaks ties in favor of safety. If the agent is uncertain whether a symptom duration meets "persistent," it should recommend the more urgent pathway rather than the less urgent one. In clinical safety, false positives (unnecessary referrals) are typically preferred over false negatives (missed cancers).

These three rules create a safety philosophy: **be strict about evidence (rule 1), be conservative about absence of evidence (rule 2), and be cautious about borderline cases (rule 3)**. Together, they guide the model toward safe recommendations even when NG12 guidance is ambiguous.

---

## 8. RAG Grounding Strategy

The prompt's RAG strategy is designed to maximize grounding and minimize parametric knowledge leakage.

The primary mechanism is the **multi-symptom search pattern**. Rather than asking the model to recall NG12 content from its parameters, we require it to search for each symptom. This means that every referral decision is traceable to a retrieved passage. If the agent recommends urgent referral for lung cancer based on cough, we can verify that the `search_ng12_guidelines` call retrieved NG12 passages linking cough to lung cancer urgency.

The secondary mechanism is the **terminology embedding strategy**. By explicitly defining terms like "persistent" and "unexplained" in the prompt, we reduce the model's reliance on parametric knowledge of these terms. When the model encounters "persistent cough" in a retrieved passage, it interprets "persistent" through the embedded definition, not through training data.

The tertiary mechanism is the **citation requirement**. The JSON schema requires `citations` that link recommendations to section IDs. This creates accountability—the agent cannot claim support without a citation. Clinicians can verify citations against the actual guideline document, ensuring the agent is not hallucinating guideline content.

The RAG strategy is not perfect. The model could still hallucinate retrieved passages or invent section IDs. But the strategy creates **multiple layers of verification**: the agent must search for evidence, embed that evidence in citations, and defend its recommendations with specific guideline passages. This layers-of-defense approach reduces (though does not eliminate) hallucination risk.

---

## 9. Design Trade-offs & Alternatives Considered

This prompt design represents a specific set of trade-offs, and alternatives were considered.

**Alternative 1: Role as "Cancer Risk Classifier"** would have been simpler—less clinical language, more machine-learning-friendly. However, we chose "Clinical Decision Support Agent" because it signals that the system supports human judgment, not replaces it. This framing is essential for regulatory compliance and clinical adoption.

**Alternative 2: Single consolidated guideline search** would reduce API calls and latency. Instead of searching once per symptom, we could search once with all symptoms concatenated. However, the multi-search approach retrieves more relevant passages—NG12 is organized by symptom and cancer site, so targeted searches perform better than consolidated ones.

**Alternative 3: Open-ended output format** would allow the model more flexibility—prose instead of JSON, narrative instead of structured reasoning. However, the strict JSON schema prevents vagueness and enables downstream integration. The cost (reduced flexibility) is worth the benefit (auditability and consistency).

**Alternative 4: Parametric knowledge as fallback** would allow the model to rely on training data when retrieved passages are sparse. However, this creates scope creep—NG12 becomes an optional layer atop general medical knowledge, rather than the authoritative source. We chose not to allow this fallback, even though it sometimes limits the agent's ability to answer edge cases.

**Alternative 5: Probabilistic urgency scores** would allow the model to express uncertainty—"75% confidence in urgent referral." However, NG12 uses categorical urgency (pathways are either 2-week, urgent, or non-urgent), so probabilistic output would introduce complexity without clinical benefit. The six-category schema matches NG12's logic.

These trade-offs were chosen to prioritize **clinical appropriateness** (adherence to NG12) and **auditability** (traceability of reasoning) over **flexibility** and **brevity**.

---

## 10. Evaluation Approach

Evaluating a clinical decision support prompt requires multiple dimensions of testing.

**Dimension 1: Guideline Fidelity** tests whether the agent's classifications match NG12's recommendations on known cases. Given a synthetic patient (e.g., 55-year-old ex-smoker with 4-week persistent cough), does the agent recommend suspected cancer pathway referral (2-week wait)? This is tested against NG12 sections 1.2 (lung cancer referral criteria) and manual expert review.

**Dimension 2: RAG Grounding** verifies that recommendations are traceable to retrieved passages. For each recommendation, trace the citations and verify that the cited NG12 sections actually support the recommendation. This test catches hallucinated citations.

**Dimension 3: Safety Rule Adherence** checks that the agent respects the three safety rules. Does it refuse to invent criteria not in NG12? Does it recommend safety netting when evidence is insufficient? Does it err on the side of caution for borderline cases? This is tested by adversarial cases—prompts designed to test rule boundaries.

**Dimension 4: Terminology Precision** verifies that NG12 vocabulary is used correctly. When the agent says "persistent," does it adhere to the embedded definition? When it says "urgent," does it mean "within 2 weeks" per NG12, not "as soon as possible" per common usage?

**Dimension 5: Cross-guideline Consistency** tests that the agent is consistent within NG12. If the same symptom in two different cancer-site sections (e.g., cough in lung vs. cough in gastric cancer) has different referral criteria, does the agent identify and apply the correct criterion for that cancer site?

**Dimension 6: Failure Mode Analysis** examines edge cases where the agent might fail. What happens when a symptom is not in NG12? (It should recommend safety netting.) What happens when the patient is outside NG12's age range? (It should note this limitation.) What happens when retrieved passages are ambiguous or contradictory? (It should highlight the ambiguity, not hide it.)

The evaluation framework is comprehensive because clinical safety demands rigor. A miscalibrated urgency classification can have serious consequences—inappropriately deferring a cancer referral or inappropriately escalating a benign presentation.

---

## Conclusion

The system prompt for the NG12 Clinical Decision Support Agent reflects careful consideration of prompt engineering principles, clinical safety requirements, and the specific constraints of language models. The four-step RETRIEVE→SEARCH→REASON→CLASSIFY process, combined with strict output formatting, terminology embedding, and multi-layered RAG grounding, creates a system that is simultaneously flexible enough to handle diverse cases and constrained enough to remain faithful to NG12's logic.

The design prioritizes **auditability** (every recommendation is traceable to guideline passages), **safety** (conservative defaults and explicit guardrails), and **clinical appropriateness** (NG12-aligned vocabulary and decision categories). While no system is perfect, this prompt architecture reduces hallucination risk, prevents scope creep, and creates a foundation for clinical adoption of AI-driven decision support in cancer risk assessment.
